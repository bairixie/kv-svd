Profiling method: We used PyTorch torch.profiler inside the full inference loop (not an isolated SVD kernel), because xKV triggers SVD during prefill cache merging. To avoid cold-start effects and huge traces, we used a profiler schedule: warm up for a few samples, then enable profiling only for a middle window (steady-state). Implementation: Evaluator.test() calls prof.step() once per sample so the schedule advances by sample. Outputs: Chrome trace (trace.json), top-ops table (prof_table.txt), and a run-config + svd_v5 stage aggregates (prof_summary.json). Stage-level breakdown uses record_function('svd_v5/...') annotations and does not change the algorithm or dtypes. Note: svd_v5 breakdown rows are aggregated by name; bucket plot uses leaf-only tags to avoid parent/child double counting.
