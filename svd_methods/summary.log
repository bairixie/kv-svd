# Randomized SVD Implementation Comparison (cholqr_v1–v4)

## 1. Overall summary

All four versions implement a **randomized SVD** with power iteration and Cholesky‑based QR, but they evolve in three key dimensions:

1. **Gram matrix construction**: how the Gram matrix  
   $G = Y^\top Y$ (or its variants) is formed, symmetrized, and regularized.
2. **Numerical stability**: dynamic jittering, normalization, and eigen‑based SPD corrections.
3. **Logging & scope**: how much latency breakdown is recorded and how well each version is tuned for BF16 / large‑scale runs.

---

## 2. Version matrix (high‑level)

| Version | Key strategy            | Stability mechanism                          | Typical behavior                 |
| ------ | ----------------------- | ------------------------------------------- | -------------------------------- |
| **v1** | Basic Cholesky QR       | Fixed jitter + QR fallback                  | Fastest, but numerically fragile |
| **v2** | Robust Cholesky         | Dynamic jitter + full `eigh` SPD fix        | Very stable, smoother curves     |
| **v3** | Cheaper SPD correction  | `eigvalsh` + eigenvalue shift before Cholesky | v2‑like stability, less overhead |
| **v4** | BF16‑optimized pipeline | Trace‑based scaling + mixed‑precision design | Best for high‑rank / BF16 use    |

---

## 3. Detailed algorithmic differences

### 3.1 `random_cholesky_v1.py` — Simple regularization

- **Characteristics**
  - Uses `chol_qr_hybrid`: builds $G = Y^\top Y + \varepsilon I$ with a **fixed** `reg_eps`.
  - **Fallback**: if Cholesky factorization of $G$ fails, falls back to `torch.linalg.qr`.
  - **Power iteration**: repeatedly applies $Y \leftarrow A A^\top Y$ (BMMs in BF16) **without explicit per‑iteration normalization**.
- **Empirical behavior**
  - Very low kernel latency (dominated by BMMs).
  - Accuracy is more sensitive to `rank` / `LGS` because the lack of normalization can amplify numerical issues.

### 3.2 `random_cholesky_v2.py` — Dynamic jitter & full eigen‑correction

- **Characteristics**
  - **Gram matrix**: explicitly symmetrizes $G \leftarrow \tfrac{1}{2}(G + G^\top)$ before Cholesky.
  - **Dynamic jitter**: uses diagonal statistics of $G$ to scale jitter, with a loop over `max_tries` and increasing regularization.
  - **SPD correction**: if repeated jitter still fails, calls `torch.linalg.eigh(G)` and rebuilds  
    $G' = Q \operatorname{diag}(\max(\lambda_i, \epsilon)) Q^\top$ to guarantee SPD.
  - **Normalization**: explicitly normalizes the power‑iteration basis vectors after each iteration (in FP32).
- **Empirical behavior**
  - Slightly higher latency than v1 when SPD correction is triggered.
  - Much smoother accuracy vs. `n_iter` / `rank` curves; no “spiky” failures in power‑iteration logs.

### 3.3 `random_cholesky_v3.py` — Cheaper SPD correction

- **Characteristics**
  - Inherits v2’s symmetrization and dynamic jitter.
  - **Optimization**: replaces full `eigh` with `torch.linalg.eigvalsh(G)` to estimate the minimum eigenvalue,
    then adds a global shift:  
    $G' = G + (\epsilon - \lambda_{\min}) I$ if $\lambda_{\min} < \epsilon$.
  - **SPD fix**: runs Cholesky on the shifted $G'$ instead of reconstructing $Q \Lambda Q^\top$.
- **Empirical behavior**
  - Lower overhead than v2 in the pathological SPD‑failure cases.
  - Accuracy curves closely match v2 (same normalization scheme).

### 3.4 `random_cholesky_v4.py` — BF16‑oriented randomized SVD for KV‑cache

- **Characteristics**
  - **Improved scaling**: uses trace‑like statistics (mean diagonal of $G$) to choose jitter scales that behave well across ranks / LGS.
  - **Eigen‑clamping (optional path)**: when using `eigh` mode, clamps any eigenvalues below a threshold  
    ($\lambda_i \leftarrow \max(\lambda_i, \epsilon)$) before reconstructing $G'$.
  - **Interface / layout**: kernels are specialized for 3D tensors `(batch, seq, dim)` or merged‑layer KV layouts,
    with inputs typically stored in BF16.
  - **Hybrid precision**: accumulations and normalization are performed in FP32 (for stability),
    then cast back to BF16 where appropriate for storage and BMMs.
- **Empirical behavior**
  - **Latency vs. `n_iter`**: grows roughly linearly with the number of power iterations, as expected for BMM‑dominated kernels.
  - **Accuracy vs. `n_iter`**: large gains from `n_iter = 2` → `8`, then diminishing returns / saturation.
  - **LGS sweeps**: clearly illustrates the trade‑off that larger layer‑group sizes (LGS)  
    increase compression and latency per call, while often reducing task accuracy.

---

## 4. Cross‑version conclusion

All four variants share the same **structural design**:

- heavy linear algebra (BMMs) in **BF16**,
- a **small FP32 SVD** on the compressed core,
- and Cholesky‑based QR as the main orthogonalization workhorse.

From **v1 → v4**, the kernels move from a fast but fragile prototype toward a **numerically robust, BF16‑optimized implementation** that is suitable for
large‑scale KV‑cache compression experiments (as used in this repository and the xKV benchmarks).